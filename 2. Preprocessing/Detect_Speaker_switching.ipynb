{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15fa09c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 1-3, 앵커 목소리가 기자 목소리로 전환될 때 timestamp 남기기\n",
    "\n",
    "# 참고 자료 : https://github.com/pyannote/pyannote-audio/tree/master/tutorials/pretrained/model\n",
    "\n",
    "# [ 고민 지점 ]\n",
    "# 연산 처리 시간이 생각보다 오래 걸리는데 이걸 어떻게 극복해야 할까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d62edfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/pyannote/pyannote-audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0358c18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YangGang\\anaconda3\\lib\\site-packages\\pyannote\\database\\database.py:51: UserWarning: Ignoring deprecated 'preprocessors' argument in AMI.__init__. Pass it to 'get_protocol' instead.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pyannote\n",
    "from pyannote.database import get_protocol\n",
    "from pyannote.database import FileFinder\n",
    "from pyannote.audio.utils.signal import Binarize\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import moviepy.editor as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "276b084c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 실행시간 측정\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33f55df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 총정리할 때 전처리 1-1 함수의 반환값으로 input 인수값 변경\n",
    "# (전처리 1-1 함수의 반환값 : 앵커 1명의 얼굴로 시작되는 영상 리스트)\n",
    "\n",
    "# MOV_to_WAV 함수 : 영상(.mp4) -> 음성(.wav) 전환 작업\n",
    "def MOV_to_WAV(MOV_Directory):\n",
    "    \n",
    "    VideoList = os.listdir(MOV_Directory) \n",
    "    WAV_Directory = './WAV'\n",
    "\n",
    "    for i in VideoList:\n",
    "        i2 = MOV_Directory + '/' + i\n",
    "        clip = mp.VideoFileClip(i2)\n",
    "\n",
    "        sound_file_name = re.sub(pattern='mp4', repl='wav', string=i)\n",
    "        sound_file_name = WAV_Directory + '/' +sound_file_name\n",
    "        clip.audio.write_audiofile(sound_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "140fac89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WAV_file_name 함수 : WAV 파일 array 반환\n",
    "def WAV_file_name(WAV_Directory):\n",
    "    SoundList = os.listdir(WAV_Directory)\n",
    "    WAV = []\n",
    "\n",
    "    for i in SoundList:\n",
    "        i2 = WAV_Directory + '/' + i\n",
    "        WAV.append(i2)\n",
    "\n",
    "    WAV = np.array(WAV)\n",
    "    \n",
    "    return WAV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21fb1250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using_sad 함수 : Speech activity detection (sad) 사전훈련 모델 사용 선언 및 설정\n",
    "# (+ WAV_file_name 함수의 반환값을 인수로 넣기)\n",
    "def Using_sad(WAV):\n",
    "    sad = torch.hub.load('pyannote/pyannote-audio', 'sad_ami')\n",
    "    preprocessors = {'audio': FileFinder()}\n",
    "    protocol = get_protocol('AMI.SpeakerDiarization.MixHeadset',\n",
    "                            preprocessors=preprocessors)\n",
    "    \n",
    "    # Speech activity detection 환경 설정\n",
    "    binarize = Binarize(offset=0.52, onset=0.52, log_scale=True,\n",
    "                       min_duration_off=0.1, min_duration_on=0.1)\n",
    "\n",
    "    # 앵커 -> 기자 넘어가는 시점 계산\n",
    "    test_file = {}\n",
    "    results = pd.DataFrame({'WAV_name':[], 'TimeStamp':[]})\n",
    "    \n",
    "    for k in WAV:\n",
    "        test_file['audio'] = k\n",
    "        sad_scores = sad(test_file)\n",
    "        speech = binarize.apply(sad_scores, dimension=1)\n",
    "    #     print(test_file['audio'], str(speech[0]))\n",
    "\n",
    "        a = str(speech[0])\n",
    "        a = re.sub(pattern='\\-\\-\\>', repl='', string=a)\n",
    "        a = re.sub(pattern='\\[', repl='', string=a)\n",
    "        a = re.sub(pattern='\\]', repl='', string=a)\n",
    "        a = str.split(a)\n",
    "        \n",
    "        b = a[1]\n",
    "        b = datetime.datetime.strptime(b, '%H:%M:%S.%f').time()\n",
    "        result = pd.DataFrame({'WAV_name':[test_file['audio']], 'TimeStamp':[b]})\n",
    "        \n",
    "        results = pd.concat([results, result])\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af6c7a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switching_moment 함수 : 전처리 1-3 파트 총망라\n",
    "def Switching_moment():\n",
    "    # mp4 -> wav 파일 변환\n",
    "    MOV_to_WAV(MOV_Directory = './MOV')\n",
    "    \n",
    "    # wav 파일 이름 구하기\n",
    "    WAV_files = WAV_file_name(WAV_Directory = './WAV')\n",
    "    \n",
    "    # 앵커 -> 기자 넘어가는 시점 계산\n",
    "    result_table = Using_sad(WAV=WAV_files)\n",
    "    \n",
    "    return result_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb6a1e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in ./WAV/readnaversid1750oid448aid0000195268.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in ./WAV/readnaversid1750oid448aid0000195576.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in ./WAV/readnaversid1750oid448aid0000196603.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in ./WAV/video.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\YangGang/.cache\\torch\\hub\\pyannote_pyannote-audio_master                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WAV_name</th>\n",
       "      <th>TimeStamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./WAV/readnaversid1750oid448aid0000195268.wav</td>\n",
       "      <td>00:02:02.546000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./WAV/readnaversid1750oid448aid0000195576.wav</td>\n",
       "      <td>00:00:13.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./WAV/readnaversid1750oid448aid0000196603.wav</td>\n",
       "      <td>00:00:26.466000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./WAV/video.wav</td>\n",
       "      <td>00:00:19.104000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        WAV_name        TimeStamp\n",
       "0  ./WAV/readnaversid1750oid448aid0000195268.wav  00:02:02.546000\n",
       "0  ./WAV/readnaversid1750oid448aid0000195576.wav  00:00:13.160000\n",
       "0  ./WAV/readnaversid1750oid448aid0000196603.wav  00:00:26.466000\n",
       "0                                ./WAV/video.wav  00:00:19.104000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Switching_moment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b95072c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:03:03\n"
     ]
    }
   ],
   "source": [
    "# 실행시간 결과\n",
    "sec = time.time()-start\n",
    "times = str(datetime.timedelta(seconds=sec)).split(\".\")\n",
    "times = times[0]\n",
    "print(times)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
